<?xml version="1.0" encoding="UTF-8"?>
<article xmlns:xlink="http://www.w3.org/1999/xlink">
  <front>
    <journal-meta>
      <journal-title-group>
        <journal-title>October</journal-title>
      </journal-title-group>
    </journal-meta>
    <article-meta>
      <title-group>
        <article-title>Kauri: Scalable BFT Consensus with Pipelined Tree-Based Dissemination and Aggregation</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <string-name>Ray Neiheiser INESC-ID</string-name>
        </contrib>
        <contrib contrib-type="author">
          <string-name>U. Lisboa</string-name>
        </contrib>
        <contrib contrib-type="author">
          <string-name>UFSC/DAS Portugal</string-name>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Brazil</string-name>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Miguel Matos INESC-ID</string-name>
        </contrib>
        <contrib contrib-type="author">
          <string-name>U. Lisboa Portugal</string-name>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Luís Rodrigues INESC-ID</string-name>
        </contrib>
        <contrib contrib-type="author">
          <string-name>U. Lisboa Portugal</string-name>
        </contrib>
      </contrib-group>
      <pub-date>
        <year>2021</year>
      </pub-date>
      <volume>2</volume>
      <fpage>6</fpage>
      <lpage>29</lpage>
      <abstract>
        <p>With the growing commercial interest in blockchains, permissioned implementations have received increasing attention. Unfortunately, the BFT consensus algorithms that are the backbone of most of these blockchains scale poorly and ofer limited throughput. Many state-of-the-art algorithms require a single leader process to receive and validate votes from a quorum of processes and then broadcast the result, which is inherently non-scalable. Recent approaches avoid this bottleneck by using dissemination/aggregation trees to propagate values and collect and validate votes. However, the use of trees increases the round latency, which ultimately limits the throughput for deeper trees. In this paper we propose Kauri, a BFT communication abstraction that can sustain high throughput as the system size grows, leveraging a novel pipelining technique to perform scalable dissemination and aggregation on trees. Our evaluation shows that Kauri outperforms the throughput of state-of-the-art permissioned blockchain protocols, such as HotStuf, by up to 28x. Interestingly, in many scenarios, the parallelization provided by Kauri can also decrease the latency. CCS Concepts: ? Computer systems organization ? Reliability; Fault-tolerant network topologies.</p>
      </abstract>
      <kwd-group>
        <kwd>Distributed Systems</kwd>
        <kwd>Fault Tolerance</kwd>
        <kwd>Blockchain</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="sec-1">
      <title>-</title>
      <p>
        The increasing popularity of blockchains in addressing an
expanding set of use cases, from enterprise to governmental
applications [
        <xref ref-type="bibr" rid="ref9">9</xref>
        ], led to a growing interest in permissioned
blockchains, such as Hyperledger Fabric [
        <xref ref-type="bibr" rid="ref5">5</xref>
        ]. In contrast to
their permissionless counterparts, permissioned blockchains
can ensure deterministic transaction finality, which is a key
requirement in many settings [
        <xref ref-type="bibr" rid="ref31">31</xref>
        ], and can ofer high
throughput in small sized systems [
        <xref ref-type="bibr" rid="ref33">33</xref>
        ].
      </p>
      <p>
        However, emerging use cases for permissioned blockchains
require the system to scale to hundreds of participants [
        <xref ref-type="bibr" rid="ref16">16</xref>
        ].
For instance, the Diem blockchain states that: ?Our goal was
to choose a protocol that would initially support at least 100
validators and would be able to evolve over time to support
500?1,000 validators" [
        <xref ref-type="bibr" rid="ref13">13</xref>
        ]. In addition to that, a recent paper
from IBM [
        <xref ref-type="bibr" rid="ref28">28</xref>
        ] discusses the need to extend HyperLedger to
support deployments above 100 nodes in order to address
the requirements of platforms such as Corda [
        <xref ref-type="bibr" rid="ref26">26</xref>
        ]. However,
most permissioned blockchains are based on variants of
classical byzantine fault-tolerant (BFT) consensus protocols that
scale poorly with the number of participants [
        <xref ref-type="bibr" rid="ref10 ref22">10, 22</xref>
        ].
      </p>
      <p>
        Such scalability limitations stem from bottlenecks both
at the network and processing levels that result from the
large number of messages that need to be sent, received and
processed to reach consensus. For instance, the well-known
PBFT protocol [
        <xref ref-type="bibr" rid="ref7">7</xref>
        ] organizes participants in a clique and uses
an all-to-all communication pattern that incurs in a quadratic
message complexity. Although there have been many
proposals to extend and improve several aspects of PBFT (such
as [
        <xref ref-type="bibr" rid="ref11 ref29 ref3 ref30">3, 11, 29, 30</xref>
        ]), most preserve its communication pattern.
      </p>
      <p>
        In HotStuf [
        <xref ref-type="bibr" rid="ref33">33</xref>
        ], only the leader sends/collects messages
directly to/from all other processes, i.e. communication is
based on a star topology centered at the leader. This approach
results in linear message complexity but the leader is still
required to receive and validate votes from at least 2 + 1
processes. At the time of this writing, the publicly available
implementation of HotStuf uses secp256k1 [
        <xref ref-type="bibr" rid="ref32">32</xref>
        ], a highly
efifcient elliptic curve algorithm that is also used in Bitcoin[
        <xref ref-type="bibr" rid="ref2">2</xref>
        ].
In this implementation, the leader has to relay the full set of
signatures to all processes. Alternatively, it is possible to use
multisignatures, such as bls [
        <xref ref-type="bibr" rid="ref4">4</xref>
        ], to reduce the message size
at the expense of additional computational load at the leader.
However, due to the centralized control, HotStuf is
inherently non-scalable: the system performance is limited by the
computing and bandwidth capacity of the leader process.
      </p>
      <p>
        One possible way to circumvent the scalability constraints
is to select a small committee such as in Algorand [
        <xref ref-type="bibr" rid="ref15">15</xref>
        ]
or SCP [
        <xref ref-type="bibr" rid="ref24">24</xref>
        ]. However, this approach either reduces the
resilience of the system (the maximum number of faults
becomes a function of the committee size and not of the entire
system size) or compromises deterministic finality (a block
can only be finalized after multiple subsequent blocks have
been produced by diferent committees, implicitly
vouching for the correctness of the result). Alternatively, systems
such as Steward [
        <xref ref-type="bibr" rid="ref1">1</xref>
        ], Fireplug [
        <xref ref-type="bibr" rid="ref25">25</xref>
        ], ResilientDB [
        <xref ref-type="bibr" rid="ref17">17</xref>
        ] or
MultiLayer PBFT [
        <xref ref-type="bibr" rid="ref23">23</xref>
        ] organize processes in hierarchical groups
to achieve low message complexity and balance the
bandwidth load. However, they sacrifice resilience by tolerating
significantly less than  = 3?1 failures.
      </p>
      <p>
        Approaches such as Byzcoin [
        <xref ref-type="bibr" rid="ref20">20</xref>
        ], Motor [
        <xref ref-type="bibr" rid="ref19">19</xref>
        ], and
Omniledger [
        <xref ref-type="bibr" rid="ref21">21</xref>
        ] address the bottleneck at the leader by
organizing processes in a tree topology, with the leader placed at
the root. The tree is used to disseminate information from
the leader to the other processes, and to aggregate votes
using cryptographic schemes such as multisignatures [
        <xref ref-type="bibr" rid="ref20 ref4">4, 20</xref>
        ].
The use of trees reduces the number of messages any single
process has to send, receive, and process (that becomes
logarithmic with the system size) by distributing the load among
all internal nodes of the tree.
      </p>
      <p>The use of trees comes, however, at the cost of an
increased latency of each consensus round. In fact, while in
PBFT a round can be executed within a single
communication step, in HotStuf it requires two communication steps
(i.e., a roundtrip), and in trees it requires 2? communication
steps, where ? is the height of the tree. If the blockchain
protocol only starts a new consensus instance after the previous
one terminates, this increase of the per-round latency has a
direct negative impact on the system throughput. In fact, the
advantages that stem from the load distribution can easily
be outweighed by the disadvantages associated with longer
consensus rounds. Strikingly, neither Motor nor Omniledger
discuss or mitigate the impact of the additional latency on
the throughput resulting from the increased number of
communication steps required to complete each round.</p>
      <p>Pipelining allows to mitigate the negative impact on
throughput of additional communication steps. In HotStuf the first
round of the ? consensus instance is executed in parallel
with the second round of the (?1)? consensus instance, and
with the third round of the ( ? 2)? consensus instance, etc.
This allows to piggyback information from multiple
consensus instances in a single message. Unfortunately, pipelining
increases the burden on the leader further amplifying the
scalability limitations of a centralized approach.</p>
      <p>
        Another disadvantage of trees is their slow recovery in the
presence of faults. In approaches that use a clique or a star
topology, such as PBFT or HotStuf, respectively, the system
is able to make progress as long as the leader is non-faulty.
Moreover, if the leader is faulty, the system is guaranteed
to recover after  + 1 reconfigurations (also known as view
changes in the literature). When using trees, progress is
guaranteed if and only if all internal nodes of the tree are
non-faulty (this is a suficient but not necessary condition as
discussed in §3). Furthermore, finding a configuration
without faulty internal nodes has combinatorial complexity [
        <xref ref-type="bibr" rid="ref19">19</xref>
        ].
Due to these challenges, Byzcoin [
        <xref ref-type="bibr" rid="ref20">20</xref>
        ] quickly falls back to
a clique when faults occur. Motor [
        <xref ref-type="bibr" rid="ref19">19</xref>
        ] and Omniledger [
        <xref ref-type="bibr" rid="ref21">21</xref>
        ]
build upon the principles of Byzcoin, but rather than falling
back immediately to a clique topology, rotate the nodes in
the subtrees in an attempt to let the leader, i.e. the root of
the tree, gather  ?  signatures. If, in a given round, the
root process is unable to collect a quorum of signatures, it
contacts directly a random subset of leaf processes, which
in turn will attempt to collect votes from their siblings,
until a quorum is obtained. Thus, in the worst case scenario,
assuming a fanout of , after  steps the root will contact

every other node directly, as if the system was using a star
topology. If the root itself fails during this process, a new
tree is formed but, if more faults occur, the entire procedure
may need to be repeated. Furthermore, this strategy only
works with trees with a maximum height of ? = 2.
      </p>
      <p>Table 1 summarizes our discussion of the systems based
on the criteria discussed above. The table highlights that
no previous system leverages load balancing techniques to
promote scalability while preserving high resilience and high
throughput. Furthermore, most systems that achieve some
form of load balancing either decrease fault tolerance or
increase the complexity of the reconfiguration leading to a
slow recovery under faults.</p>
      <p>In this paper we propose Kauri, a BFT communication
abstraction that leverages dissemination/aggregation trees
for load balancing and scalability while avoiding the main
limitations of previous tree-based solutions, namely, poor
throughput due to additional round latency and the collapse
of the tree to a star even in runs with few faults.</p>
      <p>Kauri introduces novel pipelining techniques suitable for
trees of arbitrary depth that sustain high throughput as the
system grows in size. As in HotStuf, Kauri starts a new
instance of consensus before the previous instance has
terminated. But, unlike HotStuf, Kauri starts a new round while
the previous round is still being propagated in the tree,
effectively exploiting the potential parallelism created by the
diferent stages (one stage per height) of the tree. This
allows the leader to efectively use the available bandwidth
without becoming a bottleneck. One of the key challenges
behind our combination of trees and pipelining is that
using arbitrary pipeline values results in poor performance:
under-pipelining fails to take advantage of the available
parallelization opportunities, while over-pipelining congests the
system - hence, simply using HotSuf?s star-based pipelining
in Kauri trees would not yield good results. We overcome
this challenge by introducing a performance model that
approximates, for a given scenario, the ideal pipelining values
that maximize performance.</p>
      <p>We also introduce a novel reconfiguration strategy that,
when the number of consecutive faults is small (arguably
the most common case), continues to use a tree topology
rather than falling back to a star. More precisely, for a tree
fanout of , if  &lt; , Kauri can find a robust tree-based
configuration in  +1 reconfiguration steps (which is optimal),
and fall back to a star topology only in runs where  ? 
consecutive faults occur. Thus, Kauri ofers the same
faulttolerance of traditional approaches (i.e. ensures correctness
as long as  &lt;  /3), ensures deterministic finality (unlike
committee-based solutions), and distributes the load among
internal nodes allowing it to scale with the number of nodes
and achieve high throughput. We implemented Kauri and
evaluated it under diferent realistic scenarios with up to 400
processes. Results show that Kauri outperforms HotStuf?s
throughput by up to 28x.</p>
      <p>In short, the paper makes the following contributions: i)
We present a set of abstractions that support the use of
aggregation/dissemination trees in the context of consensus
protocols; ii) We introduce a performance model that shows
how pipelining can be used to fully leverage the
parallelisation opportunities ofered by the trees; iii) We present a
precise suficient condition that allows eficient
reconfiguration of the tree without falling back immediately to a star
topology; iv) We present Kauri, the first tree-based
communication abstraction for BFT consensus protocols that achieves
higher throughput than HotStuf in all considered scenarios
and better latency under certain conditions; v) We present
an extensive experimental evaluation of Kauri in realistic
scenarios with up to 400 nodes.
2</p>
    </sec>
    <sec id="sec-2">
      <title>System Model</title>
      <p>
        We assume the system is composed of  server processes
{1, 2, . . . ,  } and a set of client processes {1, 2, . . . ,  }.
We also assume the existence of a Public Key Infrastructure
used by processes to distribute the keys required for
authentication and message signing. Moreover, processes may not
change their keys during the execution of the protocol and
require a suficiently lengthy approval process to re-enter
the system to avoid rogue key attacks [
        <xref ref-type="bibr" rid="ref27">27</xref>
        ]. We assume the
Byzantine fault model, where at most  &lt;  /3 faulty
processes may produce arbitrary values, delay or omit messages,
and collude with each other, but do not possess suficient
resources to compromise the cryptographic primitives.
      </p>
      <p>
        Processes communicate via perfect point-to-point
channels with the following properties: Validity: If a process  
delivers a value  on a channel over an edge   ,  was sent
by  . Termination: If both  and   are correct, if  invokes
send then eventually   delivers  . These are implemented
using mechanisms for message re-transmission and detection
and suppression of duplicates [
        <xref ref-type="bibr" rid="ref6">6</xref>
        ]. To circumvent the
impossibility of consensus[
        <xref ref-type="bibr" rid="ref14">14</xref>
        ], we assume the partial synchrony
model [
        <xref ref-type="bibr" rid="ref10">10</xref>
        ]. In this model, there may be an unstable period,
where messages exchanged between correct processes are
arbitrarily delayed. However, there is a known bound ? on
the worst-case network latency and an unknown Global
Stabilization Time (GST), such that after GST, all messages
between correct processes arrive within ?. Note that safety
is always preserved and the partial synchrony assumptions
are necessary only to ensure liveness [
        <xref ref-type="bibr" rid="ref33">33</xref>
        ].
3
      </p>
    </sec>
    <sec id="sec-3">
      <title>Using Dissemination/Aggregation Trees</title>
      <p>Instead of designing a completely new consensus algorithm
from scratch, we developed Kauri as an extension of HotStuf.
The key idea is to replace the dissemination and aggregation
patterns used by HotStuf, which are based on a star
topology, by new patterns based on tree topologies. While for
simplicity our presentation hinges on HotStuf
characteristics, our principles could also be applied to other leader-based
consensus algorithms.</p>
      <sec id="sec-3-1">
        <title>3.1 HotStuf Communication Pattern</title>
        <p>For self-containment, we provide a brief high-level
description of HotStuf. We give emphasis on the communication
pattern used in HotStuf and discuss how this pattern may be
abstracted, such that it can be replaced by diferent
implementations. HotStuf reaches consensus in four communication
rounds. Each round consists of two phases: i) a dissemination
phase where the leader broadcasts some information to all
processes; and ii) an aggregation phase where the leader
collects and aggregates information from a quorum of replicas.
All rounds follow the same exact pattern, but the information
sent and received by the leader in each round difers:
First round: In the dissemination phase, the leader broadcasts
a block proposal to all processes. In the aggregation phase,
the leader collects a prepare quorum of  ?  signatures
of the block. The signatures convey that the replicas have
validated and accepted the block proposed by the leader.
Second round: In the dissemination phase, the leader
broadcasts the prepare quorum. In the aggregation phase, the leader
collects the pre-commit quorum, including  ?  signatures
from processes that have validated the prepare quorum. If
the leader is able to collect a pre-commit quorum, the value
proposed by the leader is locked and will not be changed,
even if the leader is subsequently suspected.</p>
        <p>Third round: In the dissemination phase, the leader broadcasts
the pre-commit quorum. In the aggregation phase, the leader
collects a commit quorum, including  ?  signatures of
processes that have validated the pre-commit quorum. If the
leader is able to collect the quorum, the value is decided.
1: prepare 2: pre-commit 3: commit 4: decide
1: prepare
2: pre-commit
3: commit
4: decide</p>
        <p>P0
P1</p>
        <p>P2
P3</p>
        <p>P4 P5
(a) Topology</p>
        <p>C
P0
P1
P2
L1
L2</p>
        <p>L3
P6 L4
P1
P5</p>
        <p>P2</p>
        <p>P4
P6</p>
        <p>P0</p>
        <p>P3
Fourth round: In the last round, the leader broadcasts the
commit quorum to all processes, which in turn verify it and
decide accordingly.
? broadcastMsg(data). This primitive is used in the first
phase of each round to broadcast data from the leader
to all other processes.
? waitFor (N - f) votes. This primitive is used in the second
phase of each round, for the leader to collect votes from
a quorum of  ?  processes.</p>
        <p>The implementation of these primitives must satisfy the
following properties:
Definition 1. Reliable Dissemination: After the GST, and
in a robust configuration, all correct processes deliver the data
sent by the leader.</p>
        <p>Definition 2. Fulfillment: After the GST, and in a robust
configuration, the aggregate collected by the leader includes at
least  ?  votes.</p>
        <p>It is easy to show that, when using perfect point-to-point
channels, it is possible to achieve Reliable Dissemination
and Fulfillment on a star topology. For this purpose, we first
define the notion of a robust star.</p>
        <p>Definition 3. Robust Star: A star is said to be robust if the
leader is correct, and non-robust if the leader is faulty.</p>
        <p>
          Briefly, the assumption of perfect point-to-point channels
and the fact that the leader is correct ensure that all correct
processes deliver the message sent by the leader, hence
satisfying Reliable Dissemination. In a similar fashion, all correct
processes are able to send their vote to the leader which,
in turn, is able to collect  ?  votes/signatures and hence
satisfy Fulfillment. For lack of space, we refer the reader to
the HotStuf paper for full details [
          <xref ref-type="bibr" rid="ref33">33</xref>
          ].
3.2
        </p>
      </sec>
      <sec id="sec-3-2">
        <title>Using Trees to Implement HotStuf</title>
        <p>We now discuss how to implement the broadcastMsg and
waitFor primitives using tree topologies, while preserving
the same properties. As noted before, processes are organized
in a tree with the leader at the root. The primitive
broadcastMsg is implemented by having the root send data to its
children that in turn forward it to their own children, and so
forth. The primitive waitFor is implemented by having the
leaf nodes send their signatures to their parent. The parent
then aggregates those signatures with its own and sends the
aggregate to their own parent. This process is repeated until
the final aggregate is computed at the root of the tree. This
process is illustrated in Figure 2.</p>
        <p>When using a tree to implement broadcastMsg and waitFor,
the notion of robust configuration needs to be adapted, as
it is no longer enough that the leader is non-faulty to make
the configuration robust. We define a robust tree as follows.
Definition 4. Robust Tree: An edge is said to be safe if the
corresponding vertices are both correct processes. A tree is robust
if the leader process is correct and, for every pair of correct
process  and   , the path in the tree connecting these processes
is composed exclusively of safe edges.</p>
        <p>Note that our definition of a robust tree is a suficient but
not necessary condition to achieve consensus. In fact,
consensus can be reached as long as there is a path composed
exclusively of safe edges between the leader and a quorum
of correct processes. Our simpler formulation discards some
viable configurations - for instance a tree with a faulty
internal node where all its children are also faulty - but provides
an important corollary: a tree is robust if and only if all
internal nodes, including the leader, are correct processes. This
observation allows us to devise an eficient reconfiguration
algorithm that is optimal when the number of consecutive
faults is small (§5).</p>
      </sec>
      <sec id="sec-3-3">
        <title>3.3 Dissemination and Aggregation</title>
        <p>We start by describing the communication primitives used
to propagate information on the tree and the cryptographic
primitives used to perform aggregation.
3.3.1 Communicating on the Tree. Processes use the
tree to communicate. Each directed edge maps to a perfect
single-use point-to-point channel used to send and deliver
a single value. Note that, when using perfect channels, a
message is only guaranteed to be eventually delivered if
both the sender and the recipient are correct. If the sender is
faulty, no message may ever be delivered. To avoid blocking,
a process should be able to make progress if a message takes
too long to be received. Moreover, the single-use ensures
that the receiver either returns the current value sent or ?
Algorithm 1 Impatient Channels: receive
1: let ic be an impatient channel built on top of perfect channel pc
2: function ic.receive( p)
3: timer.start(?)
4: when pc.deliver (, ) do return 
5: when timer.timeout() do return ?</p>
        <sec id="sec-3-3-1">
          <title>6: end function</title>
          <p>? receive from p
and never older values. In practice, this can be achieved by
assigning a unique identifier to each instance and tagging
the corresponding messages with this identifier.</p>
          <p>This behavior is captured by an abstraction we call
impatient channels. Impatient channels ofer a blocking receive
primitive that always returns a value: either the value sent
by the sender, or a special value ? if the sender is faulty or
the system is unstable. After the GST, if the sender and the
receiver are correct, the receiver always receives the value
sent. Impatient channels have the following properties:
? Validity: If a process   delivers a value  on a channel
over an edge   ,  was sent by  or  = ?.
? Termination: If a correct process   invokes receive,
it eventually returns some value.
? Conditional Accuracy: Let  and   be correct sender
and receiver processes, respectively. After GST,  
always return the value  sent by  .</p>
          <p>Algorithm 1 shows how impatient channels can be
implemented on top of perfect channels using the known bound
? on the worst-case network latency.</p>
        </sec>
      </sec>
      <sec id="sec-3-4">
        <title>3.3.2 Cryptographic Collections. In each round of con</title>
        <p>
          sensus, it is necessary to collect a Byzantine quorum of votes.
The collection and validation of these votes can be an
impairment for scalability. Kauri mitigates these costs by using the
tree to aggregate votes as they are forwarded to the leader.
We model the process of vote aggregation with a
cryptographic collection abstraction that corresponds to a secure
multi-set of tuples (,  ). A process  can create a new
collection  with a value  by calling =new((,  )). Processes
can also merge two collections using a combine primitive
denoted by 12 = 1 ? 2. A process can also check if a collection
 includes at least a given threshold of  distinct tuples with
the same value  , by calling has(, ,  ). Finally, it is possible
to check the total number of input tuples combined in  by
checking its cardinality | |. Cryptographic collections have
the following properties:
? Commutativity: 1 ? 2 = 2 ? 1
? Associativity: 1 ? (2 ? 3) = (1 ? 2) ? 3
? Idempotency: 1 ? 1 = 1
? Integrity: Let  = 1 ? . . .  . . . . If has (, ,  ) then at
least  distinct processes  have executed  =new((,  ))
Note that diferent cryptographic techniques can be used
to implement these collections. In Kauri, we leverage a
noninteractive bls multisignature scheme that allows each
internal node to aggregate the votes from its children into
one single aggregated vote [
          <xref ref-type="bibr" rid="ref4">4</xref>
          ]. The burden imposed on each
internal node (including the root) is O (), where  is the
        </p>
        <p>
          Algorithm 2 broadcastMsg on a tree  (process  )
1: procedure broadcastMsg( , data)
2: children ?  .children( )
3: parent ?  .parent( )
4: if parent ? ? then
5: data ? ic.receive(parent)
6: end if
7: for all e ? children do
8: ic.send(, data)
9: end for
10: return data
11: end procedure
fanout of the tree and the complexity of verifying an
aggregated vote is O (1). Note that classical asymmetric signatures
require O ( ) verifications at each process [
          <xref ref-type="bibr" rid="ref4">4</xref>
          ].
3.3.3 Implementing broadcastMsg. The implementation
of broadcastMsg on a tree is presented in Algorithm 2. Note
that the algorithm always terminates, even if some
intermediate nodes are faulty. This is guaranteed since impatient
channels always return a value after the known bound ? on
the worst-case network latency, either the data sent by the
parent or the special value ?.
        </p>
        <p>Theorem 1. Algorithm 2 guarantees Reliable Dissemination.
Proof. We prove this by contradiction. Assume Reliable
Dissemination is not guaranteed. This implies that at least one
correct process did not receive the data sent by the leader.
This is only possible if: i) at least one correct process is not
connected to the leader either directly or through correct
intermediary processes, ii) one of the intermediary processes
or the root process did not invoke channel.send for at least
one correct child process, or iii) the data got lost in the
channel. Reliable Dissemination is defined only for a robust
conifguration which, following the definition of a Robust Tree,
ensures that the leader is correct and there is a path of correct
processes between the leader and any other correct process.
Thus, the first case is not possible. Moreover, correct
processes follow the algorithm and, because correct processes
can only have correct parents in a robust configuration, the
second case is also impossible. Finally, the third case is also
impossible due to the use of perfect channels. Therefore,
Algorithm 2 guarantees Reliable Dissemination. ?
3.3.4 Implementing waitFor. Algorithm 3 presents the
implementation of waitFor on a tree. The algorithm relies
on the cryptographic primitives to aggregate the signatures
as they are propagated toward the root. Like broadcastMsg,
waitFor always terminates, even if some nodes are faulty.
This is guaranteed because impatient channels always return
a value after the known bound ? on the worst-case network
latency, either the data sent by the child processes or the
special value ?. Before GST or in non-robust configurations,
the collection returned at the leader may be empty or include
just a subset of the required signatures.</p>
        <p>Theorem 2. Algorithm 3 guarantees Fulfillment.
Algorithm 3 waitFor on a tree  (process  )
1: procedure waitFor( , input)
2: children ?  .children( )
3: parent ?  .parent( )
4: collection ? new( (, input))
5: for all e ? children do
6: partial ? ic.receive()
7: collection ? collection ? partial
8: end for
9: if parent ? ? then
10: ic.send(parent, collection)
11: end if
12: return collection
13: end procedure
Proof. We prove this by contradiction. Assume that the leader
process was unable to collect  ?  signatures. Following
Algorithm 3, this means that either: i) an internal node did not
receive the signatures from all correct children (line 6), ii) or
an internal node did not aggregate and relay the signatures
it has received from its correct children (line 10). Since we
assume impatient channels, that are implemented on top of
perfect point-to-point channels, the first case is not possible
after GST. The second case may happen, if either the internal
node omits signatures in the aggregate, does not relay any
signatures, or is blocked waiting indefinitely for messages
from its children. Either option leads to a contradiction. Since
we assume a robust graph, all internal nodes between the
root and a correct process must be correct and hence follow
the algorithm. Additionally, due to the impatient channels,
eventually each channel will return a value to the internal
node making sure that eventually it will unblock and
relay all collected signatures from all correct child processes.
Therefore Algorithm 3 guarantees Fulfillment. ?</p>
      </sec>
      <sec id="sec-3-5">
        <title>3.3.5 Challenges of Using a Tree. The implementations</title>
        <p>of the broadcastMsg and waitFor primitives that we
introduced above allow us to replace the star topology used in
HotStuf with a tree topology that is more eficient and scalable
as we show in the evaluation (§7). However, two remaining
challenges need to be addressed to make the tree topology a
valid alternative in practice:
Mitigate the increased latency: While trees allow to distribute
the load among all processes, the additional round-trip of
the broadcastMsg and waitFor primitives result in additional
latency, which might negatively afect system throughput.
We discuss how to mitigate this in §4.</p>
        <p>Reconfiguration strategy: In HotStuf, the configuration is
robust if the leader is non-faulty. Therefore, there are only 
non-robust configurations and  ?  robust configurations. It
is thus trivial to devise a reconfiguration strategy that yields a
robust configuration in an optimal number of steps (i.e.  + 1).
In a tree, a configuration is robust if the root and all internal
nodes are correct. The total number of configurations and
the subset of non-robust configurations is extremely large. In
§5 we introduce a reconfiguration strategy that builds robust
configurations in a small number of steps.
4</p>
      </sec>
    </sec>
    <sec id="sec-4">
      <title>Mitigating Tree Latency</title>
      <p>In this section we introduce the mechanisms to mitigate the
additional latency inherent to tree topologies when compared
to HotStuf?s star topology. As described earlier, HotStuf
needs four communication rounds for each instance of
consensus. If HotStuf waited for each consensus instance to
terminate before starting the next one, the system
throughput would sufer significantly. Therefore, HotStuf relies on
a pipelining optimization, where the  + 1 instance of
consensus is started optimistically, before instance  is terminated.
As a result, at any given time, each process participates in
multiple consensus instances. Furthermore, to reduce the
number of messages, HotStuf combines the information of
these parallel consensus instances in a single message.</p>
      <p>By following the same structure, Kauri is amenable to the
same optimization. However, because Kauri uses a tree, the
latency to terminate a given round (and hence a consensus
instance) is substantially larger than in HotStuf. While at
ifrst this might look like an obstacle, it opens the door for
more advanced pipelining techniques that substantially
improve throughput and hide the additional latency induced by
trees. In fact, as we will show in the evaluation (§7), in certain
scenarios, Kauri can achieve not only higher throughput, but
also lower latency than HotStuf.
4.1</p>
      <sec id="sec-4-1">
        <title>Pipelining in HotStuf</title>
        <p>We start by providing an overview of HotStuf?s pipelining
using the seven node scenario previously introduced in
Figure 1. Figure 3 illustrates the execution of multiple rounds
of consensus in HotStuf where each round is depicted in a
diferent shade of gray.</p>
        <p>Consider the first round (light gray) that starts with the
leader sending the block to all other processes (downward
arrows). The time this step takes depends on the size of the
data being transmitted, the available bandwidth, and the
total number of nodes. To conclude a round, the leader has to
collect a quorum of signatures. These signatures start
flowing toward the leader as soon as the first process receives
the message from the leader (upward arrows). Therefore,
in a given round, dissemination and aggregation are
partially executed in parallel. Soon after the dissemination of a
round finishes, the leader may already start the next round
of consensus.</p>
        <p>To implement pipelining, HotStuf optimistically starts a
new instance of consensus by piggybacking the first round
messages of the next consensus instance with the second
round messages of the previous instance. Because HotStuf
requires four rounds of communication, this process can be
repeated multiple times, resulting in messages that carry
information of up to four pipelined consensus instances. In
HotStuf the pipelining depth (i.e. the maximum number of
consensus instances that can run in parallel) is thus equal to
the number of communication rounds.
Sending time Remaining time</p>
        <p>Computation time
Instance 1,Round 1</p>
        <p>IInnssttaannccee 21+,, RRoouunndd 12</p>
        <p>IIInnnssstttaaannnccceee 213++,,, RRRooouuunnnddd 231</p>
      </sec>
      <sec id="sec-4-2">
        <title>4.2 Pipelining in Kauri</title>
        <p>In Kauri, we extend pipelining to fully leverage the load
balancing properties of trees as illustrated in Figure 4. In a tree,
the fanout  is much smaller than the number of nodes  ,
and therefore in Kauri the root completes its dissemination
phase much faster than in HotStuf, and it may become idle
long before it starts collecting votes. This allows the root to
start multiple instances of consensus during the execution
of a single consensus round. This introduces a multiplicative
factor that we call the pipelining stretch that augments the
pipelining depth of HotStuf. In the example of Figure 4, the
leader is able to start 3 new instances during the execution
of the first round of a given consensus instance. Note that,
in this example, the messages from the second round of
instance 1 are piggybacked with messages from the first round
of instance 4, i.e. a message carries information from
consensus instances/rounds that are farther away in the pipeline.
This increase in the pipelining depth allows for a higher
degree of parallelism, and hence throughput.</p>
      </sec>
      <sec id="sec-4-3">
        <title>4.3 Pipelining Stretch and Expected Speedup</title>
        <p>Kauri?s pipelining stretch, i.e. the number of instances that
can be initiated during a single round, is afected by the
following parameters:
Sending time: the time a node takes to send a block to all its
children. This value is a function of the fanout , the block
size , and the link bandwidth , and is approximated by  .</p>
        <p>Processing time: the time a node takes to validate and/or
aggregate the votes it receives from its children. This heavily
depends on the type of signatures used by the algorithm. We
measured these values experimentally, for diferent signature
schemes (see §7).</p>
        <p>Remaining time: the time that elapses from point the root
ifnishes sending the block to its children until it receives and
processes the last reply. This value is a sum of the network
latency and the processing time as defined above. It is roughly
given by:</p>
        <p>remaining time = ? · (RTT + processing time)
where ? is the height of the tree and RTT is the network
roundtrip time. In a star topology the remaining time is small
and mainly used to collect and process replies. However, in
a tree, the root is often idle for most of the remaining time.</p>
        <p>Kauri leverages this larger remaining time to start
additional consensus instances. The challenge is therefore to
estimate how many additional instances can be started, i.e.
to estimate the pipelining stretch. For presentation simplicity,
we assume that sending and processing can be performed
concurrently. In a system where the bottleneck is the
bandwidth, i.e. where the sending time is much larger than the
processing time, the number of additional consensus instance
that can be started during the remaining time is given by:
remaining time . Similarly, in a system where the bottleneck is the
sending time
CPU, i.e. where the processing time is much larger than the
sending time, the number of additional consensus instances
that can be started during the remaining time is given by:
remaining time .
processing time</p>
        <p>Kauri?s pipelining stretch allows us to make the best use
of the time the leader saves by having to interact with just 
nodes instead of  ? 1 nodes. Therefore, the ratio between
 ? 1 and  defines the maximum speedup we can achieve
by using a tree instead of a star. For instance, in a system of
400 nodes, organized in a tree with fanout 20, the maximum
speedup we can expect Kauri to ofer is 19.95.
5</p>
      </sec>
    </sec>
    <sec id="sec-5">
      <title>Reconfiguration</title>
      <p>We now discuss Kauri?s reconfiguration strategy. Recall that,
in Kauri, processes use a tree to communicate. Due to faults or
an asynchronous period, the tree may be deemed not robust
and therefore a reconfiguration procedure is necessary to
build a new tree. Naturally, not all possible trees are robust
and several reconfigurations might be necessary before a
robust tree is found.</p>
      <p>Note that any leader-based protocol may require  + 1
reconfigurations to find a robust topology, given that 
consecutive leaders may be faulty. Our challenge is to avoid
making the reconfiguration of Kauri superlinear with the
number of processes, while also avoiding to fall back
immediately to a star topology as soon as a single fault occurs.</p>
      <p>We conjecture that building a general reconfiguration
strategy that yields a robust tree in a linear number of steps
without falling back to a star topology is impossible, due
to the large number of non-robust configurations that may
occur in a tree. Consider, for instance, the case of binary trees
where the number of possible binary trees is given by the
Catalan number  = ((2+1))!! ! . From all these trees, only a
small fraction is robust, namely those where faulty processes
are not internal nodes (Definition 4). Thus, a reconfiguration
strategy that considers all possible configurations may
require a factorial number of steps to find a robust tree. We
discuss our reconfiguration strategy next.</p>
      <sec id="sec-5-1">
        <title>5.1 Modeling Reconfiguration as an Evolving Graph</title>
        <p>We model the sequence of trees as an evolving graph, i.e.
a sequence of static graphs (that are trees). To ensure that
eventually a robust tree is used, the evolving graph must
observe the following property:
Definition 5. Recurringly Robust Evolving Graph: An
evolving graph G is said to be recurringly robust if robust
static graphs appear infinitely often in its sequence.</p>
        <p>A recurringly robust evolving graph is suficient to ensure
that a robust graph will eventually be used by processes
to communicate. However, this is undesirable in practice
because the number of reconfigurations until a robust graph
is found is unbounded. Because the system is essentially
halted during reconfiguration, we would like to find a robust
graph after a small number  of reconfigurations. We call this
property of an evolving graph  -Bounded conformity.
Definition 6.  -Bounded Conformity: a recurringly robust
evolving graph G exhibits  -Bounded conformity if a robust
static graph appears in G at least once every  consecutive
static graphs.</p>
      </sec>
      <sec id="sec-5-2">
        <title>5.2 Achieving t-Bounded Conformity</title>
        <p>We now introduce an algorithm that achieves  -Bounded
Conformity. We split all processes into  disjoint bins, each
of size greater or equal to  , where  is the number of
internal nodes in a tree. Then we build an evolving graph by
creating trees whose internal nodes are drawn exclusively
from a given bin, i.e., each tree   is built by picking a bin
 , following a round robin strategy, and by assigning nodes
from bin  to all internal nodes of the tree (including the
root) as depicted in Algorithm 4.</p>
        <p>Theorem 3. Algorithm 4 constructs an evolving graph that
satisfies t-Bounded Conformity as long as  &lt;  .</p>
        <p>Proof. Because the  bins are disjoint and there are at most
 &lt;  faults, at least one of the bins is composed exclusively
of correct nodes. In each  consecutive steps, the algorithm
picks a tree whose internal nodes are drawn from distinct
bins, hence guaranteeing that a robust tree is found. ?</p>
        <p>Algorithm 4 Construction of an Evolving Tree with
tBounded Conformity
1: Initially, split the set of processes N into  + 1 disjoint bins
2: N ? 0 ? 1 ? . . . ?   ; s.t. | | ?  + 1 ?  ?  = ?.
3: function build()
654::: G??? pamlilcokpdoas(nsyib+tlre1et)erefreosmwhGose internal nodes are drawn exclusively from  .
7: return</p>
        <sec id="sec-5-2-1">
          <title>8: end function</title>
          <p>A limitation of the approach is that each bin must be large
enough to contain at least as many processes as the number
of internal nodes of a tree. This limits the number of bins
that can be generated and, therefore, the maximum value
for  . In a balanced tree of fanout  we can, at most, obtain
 disjoint bins with enough capacity to fill all the internal
positions, such that this algorithm allows us to achieve at
most ( ? 1)-Bounded Conformity.
5.3</p>
        </sec>
      </sec>
      <sec id="sec-5-3">
        <title>Gracefully Degraded Reconfiguration</title>
        <p>Given that Algorithm 4 can only achieve ( ? 1)-Bounded
Conformity, if  ?  we will not be able to reconfigure
the system in an optimal number of steps. Therefore, we
adopt the following pragmatic approach to reconfiguration:
we execute Algorithm 4 and if after  steps a robust tree is
not found, Kauri falls back to a star. Thus, in the worst case
scenario, Kauri performs  +  + 1 reconfigurations until a
star with a non-faulty leader is found.</p>
        <p>When the number of actual faults is small, i.e. if  &lt;
, Kauri recovers quickly without losing its scalability and
throughput properties. If the number of faults is large, i.e. if
 ?  &lt;  /3, the system still recovers in a linear number of
steps, but falls back to the performance of the original (star
based) HotStuf protocol.</p>
      </sec>
    </sec>
    <sec id="sec-6">
      <title>6 Implementation</title>
      <p>
        We have implemented Kauri by extending the publicly
available HotStuf implementation 1. The core of the efort was
extending the code to include the implementation of the
broadcastMsg and waitFor primitives, as specified in
Algorithm 2 and Algorithm 3, respectively. We also added support
for the bls cryptographic scheme by including the publicly
available implementation used in the Chia Blockchain [
        <xref ref-type="bibr" rid="ref4 ref8">4, 8</xref>
        ].
This allows internal nodes to aggregate and verify the
signatures of their children, and thus balance the computational
load. Both the verification cost of the signature aggregates,
and the size of aggregates have a small O (1) complexity,
contributing to the overall eficiency of the implementation.
      </p>
      <p>Because HotStuf and Kauri share the same codebase, we
also implemented a variant of HotStuf that uses the bls
signature scheme. As we discuss in more detail in the next
section, this allows us to assess the efects of our
contributions versus simply adopting another cryptographic scheme
1Available at htps://github.com/hot-stuf/libhotstuf
in HotStuf. We denote the original HotStuf implementation
as HotStuf-secp and the bls variant as HotStuf-bls .
Pipelining: To implement pipelining, we use an estimation of
the parameters discussed in §4 to compute the ideal time to
start the dissemination phase for the next consensus instance.
In the current implementation, we use a static pre-configured
value but this could be automatically adapted at runtime,
which we leave for future work.</p>
      <p>
        Reconfiguration: To trigger reconfigurations we leverage the
existing HotStuf mechanisms. In detail, if no consensus is
reached after a timeout, each process compiles a new-view
message that includes the last successful quorum it observed
and sends it to the next leader [
        <xref ref-type="bibr" rid="ref33">33</xref>
        ]. In turn, the candidate
leader waits for 2 + 1 new-view messages and, depending on
the collected information, either continues the work of the
previous leader (if a block was previously locked) or proposes
its own block (if no block had been locked yet). Similarly,
in Kauri and upon timeout, each process invokes the build
function of Algorithm 4 to construct the next tree and sends
the same new-view message to the root of the new tree. The
root then also awaits 2 + 1 new-view messages before
reinitiating the protocol. Note that the new-view messages do
not use the tree and are instead sent directly to the candidate
leader as in HotStuf. This is the only time in Kauri where
all processes communicate directly with the leader.
Code Availability: Overall, the implementation of the
functionalities described above required the addition/adaptation
of ? 1300 loc to the HotStuf codebase 2.
7
      </p>
    </sec>
    <sec id="sec-7">
      <title>Evaluation</title>
      <p>In this section we evaluate Kauri across several scenarios.
7.1</p>
      <sec id="sec-7-1">
        <title>Experimental Setup</title>
        <p>
          All experiments were performed on the Grid?5000 testbed [
          <xref ref-type="bibr" rid="ref12">12</xref>
          ].
We used 20 physical machines, each with two Intel Xeon
E52620 v4 8-core CPUs and 64 GB RAM. We deploy a variable
number of processes (from 100 to 400) in these machines. As
we will discuss later, in some configurations Kauri is able to
saturate the hardware resources of our testbed.
        </p>
        <p>
          We evaluate Kauri on a wide range of deployments, that
capture the diferent scenarios where we believe that
permissioned blockchains with a large number of participants
are likely to be used. More precisely, we consider the
following deployment scenarios: global, regional, and national. The
global deployment models a globally distributed blockchain
as used in other works [
          <xref ref-type="bibr" rid="ref15 ref19 ref20">15, 19, 20</xref>
          ] with 200 roundtrip
time (RTT) and 25/ bandwidth. The two other
scenarios model reported industry use cases [
          <xref ref-type="bibr" rid="ref9">9</xref>
          ] in more limited
geographical deployments such as local supply-chain
management. The regional deployment captures a deployment in
a large country or unions of countries, such as the US or the
2Available at htps://github.com/Raycoms/Kauri-Public
        </p>
        <p>
          EU, with 100 RTT and 100/ bandwidth. The national
deployment models a setting where nodes are closer to each
other with 10 RTT and 1000/ bandwidth. Finally, we
also consider a heterogeneous deployment with a mix of
different bandwidth and RTT characteristics, as used in other
recent works[
          <xref ref-type="bibr" rid="ref17">17</xref>
          ]. We model the network characteristics of
each scenario using NetEm[
          <xref ref-type="bibr" rid="ref18">18</xref>
          ].
        </p>
        <p>
          For most experiments, we use three system sizes with
 = 100, 200, 400 processes. As expected in most realistic
deployments, these values of  do not yield perfect -ary
trees. Therefore, we simply assign processes to tree nodes
such that it approximates a balanced tree. Unless otherwise
stated, this results in the following trees: for  = 100,  = 10
for the root and  = [
          <xref ref-type="bibr" rid="ref8 ref9">8, 9</xref>
          ] for the other internal nodes; for
 = 200 the root?s fanout is  = 14, and for the other internal
nodes  = [
          <xref ref-type="bibr" rid="ref13 ref14">13, 14</xref>
          ], and for  = 400,  = 20 for the root and
 = [
          <xref ref-type="bibr" rid="ref18 ref19">18, 19</xref>
          ] for the remaining internal nodes. This results in
trees with height 2 that are used throughout the experiments,
unless otherwise stated.
7.2
        </p>
      </sec>
      <sec id="sec-7-2">
        <title>Configuring Kauri</title>
        <p>We now describe the values that are used to configure Kauri.
Table 2 shows the values of the diferent parameters
required to compute the Kauri pipelining stretch, following
the rationale introduced in §4.3. We consider diferent
bandwidth/RTT scenarios and blocks of 250 (plus signatures).
For each configuration we present the processing time, which
we have measured experimentally, the sending time, and the
remaining time (§4.3). These values are used to compute
both the target pipelining stretch and the expected
maximum speedup for each configuration. Note that, due to space
constraints, Table 2 does not include the parameter values
for all configurations we evaluate in the following sections.
For instance, we have also experimented with block sizes
diferent than 250. The purpose of the table is not to be
exhaustive but to ofer a conceptual framework that makes
it easier to reason about the experimental results presented
in the next sections.
7.3</p>
      </sec>
      <sec id="sec-7-3">
        <title>Efect of Pipelining Stretch on Throughput</title>
        <p>We start by showing the efects of the pipelining stretch on
Kauri?s throughput.</p>
        <p>Figure 5 depicts the throughput achieved when using Kauri
in a setting with  = 100 in the global scenario (200
RTT and 25/ bandwidth) for diferent block sizes and
increasing pipelining stretch values.</p>
        <p>For a blocksize of 250, the experimental numbers are
close to the numbers predicted by our model and presented
in Table 2 (3rd line for Kauri), i.e. the best results are achieved
with a pipelining stretch close to 5. This shows that our
performance model, albeit simple, can ofer a good estimate of
the performance of the real system. The figure also shows
that, with smaller block sizes, higher pipelining stretch
values are needed to make full use of the resources. This is also
o
i
r
a
n
e
c</p>
        <p>S
National
Regional
Global
Global
Global
tr(ouhhpguTK 2104356
0
2
4
6
50Kb
100Kb
200Kb
250Kb
8 10 12 14 16 18 20</p>
        <p>Pipelining Stretch
expected given our model: with smaller block sizes the
sending time is smaller and the idle portion of the remaining time
is much larger. The ratio between these two values is also
larger, thus allowing Kauri to start more instances while it
waits for the responses from a previous instance. Naturally,
it is more eficient to run fewer instances with more
transactions each than many instances with a small number of
transactions. For the rest of the evaluation, we use a blocksize
of 250 for Kauri. For HotStuf, we empirically observed
that a blocksize of 250 also yielded the best results across
the diferent experiments.</p>
      </sec>
      <sec id="sec-7-4">
        <title>7.4 Throughput Across Diferent Scenarios</title>
        <p>
          We now compare the throughput of Kauri with HotStuf-secp,
the standard implementation, and our variant HotStuf-bls,
in the national, regional and global scenarios. To assess the
impact of our pipelining scheme we also include results for
Kauri without pipelining (denoted as Kauri-np). By using
trees with BLS signatures but without pipelining, Kauri-np
captures the performance characteristics of existing
nonpipelining tree based systems such as Motor [
          <xref ref-type="bibr" rid="ref19">19</xref>
          ] and
Omniledger [
          <xref ref-type="bibr" rid="ref21">21</xref>
          ]. The results are depicted in Figure 6.
        </p>
        <p>The first observation is that, as expected, HotStuf is
extremely sensitive to the available bandwidth and to the total
number of nodes in the system. The larger the number of
nodes, the longer it takes for the leader to finish a given
100 150 200 250 300</p>
        <p>Processes
(c) global (200 RTT - 25/ links)
350
round. Also, for a fixed value of  , the sending time increases
sharply as the network bandwidth decreases. As a result,
the performance of HotStuf is highly penalized in systems
with large numbers of participants and limited bandwidth.
Also, since the use of bls signatures reduces bandwidth
usage, HotStuf-bls performs better than HotStuf- secp in all
scenarios, except when using the 1/ network.</p>
        <p>A second observation is that, without our pipelining
techniques, the performance of tree-based algorithms is mainly
limited by the RTT. This is illustrated by Kauri-np where
the throughput drops significantly when the RTT increases
but only drops slightly with the number of processes. It is
also interesting to observe that, as the network bandwidth
decreases, even without our pipelining, the use of a tree
already pays of. In fact, in the regional scenario, Kauri-np
ofers better throughput than HotStuf for a system with 200
or more processes.</p>
        <p>Kauri, by leveraging the full capacity of the system via our
pipelining mechanism, outperforms both HotStuf variants
and Kauri-np in all scenarios. Interestingly, despite the
simplifications adopted in our model (which, for instance,
considers that computation and dissemination do not interfere
with each other) the predicted speedup over HotStuf-secp is
very close to the observed value. For instance, from Table 2
Kauri
we expected a speedup over HotStuf-secp of approximately
? 30 for the system of 400 nodes in the global scenario and
the value obtained experimentally is 28.2 . This diference is
quite reasonable given the number of simplifications adopted
in the model. Overall, while the use of trees (Kauri-np) results
in better performance than stars in certain scenarios, only
the combination of trees and pipelining permits to achieve a
substantial performance increase.</p>
        <p>Note that the results of Kauri for the national scenario do
not match the predictions of our model, which predicts a
speedup of ? 6 with 400 processes. This is due to the
limitations of our testbed that does not have capacity to support
this experiment without incurring in a CPU bottleneck (note
that due to the limited number of physical servers we are
forced to collocate several process per server). In the plot
and the rest of the evaluation we highlight the data points
obtained in a saturated testbed with a red circle.</p>
        <p>Finally, note that due to the use of a tree with a fixed height
of ? = 2, Kauri?s throughput drops with the number of
processes. In §7.8 we show how throughput can be preserved by
increasing the height of the tree (and the pipelining stretch).</p>
      </sec>
      <sec id="sec-7-5">
        <title>7.5 Efect of the RTT in Throughput</title>
        <p>Pipelining not only allows Kauri to better exploit the
available computing and network resources, but also contributes
to mitigating the negative efects of additional RTT inherent
in tree-based approaches. To further assess this, we
conducted an experiment where we observe the throughput
evolution as the RTT increases.</p>
        <p>Figure 7 shows the results for N=100 in the regional
scenario (100/ bandwidth) but where we varied the RTT
from 50 to 400. As it can be observed, while the
throughput of HotStuf-secp decreases as the RTT increases, the
throughput of Kauri can be kept almost constant by
increasing the pipelining stretch to avoid the leader from being
idle while waiting for the replies. Following our model, the
pipelining stretch varied from 7, for an RTT of 50, to 33
for an RTT of 400. Results for the other scenarios (not
shown due to space constraints) follow a similar trend.</p>
      </sec>
      <sec id="sec-7-6">
        <title>7.6 Latency</title>
        <p>The previous experiments showed that Kauri, despite using
longer rounds, can achieve better throughput than HotStuf
1400
1200
)s 1000
(ycnem 860000
tLa 240000
0</p>
        <p>Kauri
HotStuff-secp</p>
        <p>HotStuff-bls
25
50</p>
        <p>100 1000
Bandwidth (Mb/s)
?
due to the use of the pipelining stretch. We now conduct a
similar study on latency.</p>
        <p>Given that the use of a tree increases the latency required
to exchange messages among the leader and the
remaining processes, one could expect that Kauri would exhibit
higher system latency than HotStuf. In fact, in a system
with unlimited bandwidth and processing power, the latency
of consensus is bound by the RTT. However, in realistic
settings, bandwidth is not infinite and in practice, the
system latency is limited by the sending time. The
dissemination/aggregation parallelism enabled by a tree substantially
reduces the sending time. This is particularly important in
bandwidth constrained scenarios where the sending time has
a much larger impact on latency than the additional number
of communication hops required by a tree.</p>
        <p>To confirm this we set up a scenario with a fixed RTT of
100 and vary the bandwidth from 25/ to 1000/.
Figure 8 shows the results for  = 100. As shown, the
available bandwidth has a much larger impact on HotStuf-secp
than in Kauri. In fact, for bandwidths smaller than 100/
Kauri ofers better latency than Hotstuf-secp, and only at
high bandwidths HotStuf-secp starts to have substantially
better latency. The pictures also shows (analytical) values for
an idealized scenario of infinite bandwidth, where
HotStufsecp?s latency would be at best half of Kauri?s. As in §7.5,
results for the other system sizes (not shown due to space
constraints) follow a similar trend.</p>
      </sec>
      <sec id="sec-7-7">
        <title>7.7 Throughput vs Latency</title>
        <p>We now study the impact of load in the performance of the
system. To this end we fix the system size, network
bandwidth and latency, and vary the load in the system by
manipulating the block size, i.e. the number of transactions
ofered by the client. Results are depicted in Figure 9 for the
global scenario with  = 100 and the following block sizes:
32 64, 125, 250, 500, and 1. For Kauri we
adjust the pipelining stretch for each scenario following our
performance model.</p>
        <p>Following the observations of the previous experiments,
the throughput of Kauri is substantially higher than that of
both variants of HotStuf in all scenarios. As the block size
increases, the latency of all systems increases as expected
due to an increase in the sending time. This increase is
however much faster in both variants of HotStuf, and for block
8192
)s 4096
(m 2048
cy 1024
tena 521526
L 128
100</p>
        <p>Kauri
HotStuff-secp
sizes larger than 125 HotStuf?s latency surpasses that
of Kauri. This highlights the importance of using a tree to
spread the load and hence avoid a bottleneck at the leader
process. HotStuf-bls outperforms HotStuf-secp in both
latency and throughput for all scenarios, which also confirms
the previous experiments when varying the available
bandwidth (Figure 8). Finally, the decrease in latency in Kauri
when going from a block sizes of 32Kb to 64Kb (the two
ifrst data points in the Kauri line) is due to pipelining efects
on CPU usage. Blocks of 32Kb allows for a higher level of
pipelining, which saturates the CPU. As the block size
increases, the pipeline decreases, following our performance
model (hence, gradually shifting the bottleneck away from
the CPU and to the network).</p>
      </sec>
      <sec id="sec-7-8">
        <title>7.8 Impact of Tree Height in Throughput/ Latency</title>
        <p>The experiments of the previous sections have shown that
the sending time is a key factor for both throughput and
latency. By reducing the sending time, Kauri provides better
throughput in all considered scenarios and better latency in
bandwidth constrained scenarios.</p>
        <p>We now study the impact of tree height on throughput
and latency by setting an experiment with  = 100, an RTT
of 100, and variable bandwidth. We deployed
HotSufsecp, HotStuf-bls (with ? = 1 and  = 99), and two Kauri
configurations: one with ? = 2 and  = 10, as in the previous
experiments, and another with ? = 3 and  = 5.</p>
        <p>Results are shown in Figure 10. The first observation is that
by increasing the tree height it is possible to substantially
increase Kauri?s throughput, which almost doubles, with only
a modest impact on latency. The results for Kauri with ? = 2
at 1/ bandwidth and ? = 3 at 100 and above saturate
our testbed, which is denoted by the red circle. According
to our model, for ? = 2 we expect the throughput to double
when moving from a 100/ bandwidth to 1/. Similarly,
for ? = 3, we expect the throughput obtained with a
bandwidth of 50/ to double and quadruple with a bandwidth
of 100/ and 1/, respectively.</p>
        <p>The second observation corroborates the experiments of
§7.6 by showing that the latency of both variants of HotStuf
vary substantially with the available bandwidth whereas
Kauri?s are much less afected. Finally, we can also see that
HotStuf-bls can outperform HotStuf-secp in certain
scenarios but only for a small margin as both systems share the
same sending time characteristics. To achieve a substantial
improvement one needs to drastically reduce the sending
time through the use of trees, and maximize resource usage
through the use of pipelining.</p>
      </sec>
      <sec id="sec-7-9">
        <title>7.9 Heterogeneous Networks</title>
        <p>
          So far we have only considered homogeneous networks,
where all links have the same characteristics. We now
consider an heterogeneous setup, where participants are
deployed in local clusters (with very low RTT and high
bandwidth within each cluster) connected over the Internet (with
varying bandwidth and RTT between clusters). For this
purpose, we adopted the scenario used in the evaluation of
ResilientDB [
          <xref ref-type="bibr" rid="ref17">17</xref>
          ] in a system with  = 60. This allows us to
compare the performance of Kauri with the results published for
ResilientDB (we did not run ResilientDB ourselves because,
at the time of this submission, the public implementation of
ResilientDB?s GeoBFT protocol was not yet available). When
deploying Kauri, we used a tree where the leader is placed
in the cluster with the highest bandwidth and lowest RTT to
every other cluster (i.e. Oregon) and the internal nodes are
located closely to their leaf nodes. Similarly, for the HotStuf
variants, the leader is located in Oregon.
        </p>
        <p>Results are depicted in Figure 11. As can be observed,
Kauri?s throughput substantially outperforms all other
systems. This is due to the high RTT, which allows Kauri to
pipeline several consensus instances in parallel and hence
achieve high throughput. In terms of latency, both HotStuf
variants outperform Kauri because the system size is small
and hence bandwidth does not become a bottleneck.
However, HotStuf latency would quickly grow with the system
as bandwidth becomes the bottleneck, while Kauri?s latency
would remain largely unafected. Nonetheless, we stress that
Kauri achieves ? 10 higher throughput than HotStuf
variants with only a ? 2 increase in latency. Interestingly, the
performance of Kauri-np is the worse of all systems. This is
because without pipelining the high RTT negatively afects
the remaining time, which ultimately limits throughput.</p>
        <p>
          Note that the Hotstuf-secp throughput results we
obtained are substantially lower than those reported in
ResilientDB. This is because ResilientDB?s authors [
          <xref ref-type="bibr" rid="ref17">17</xref>
          ] run
Kauri
) 60
/txs 50
(K 40
tpu 30
gh 20
u
ro 10
hT 0
        </p>
        <p>Kauri?np</p>
        <p>
          HotStuff?bls
 independent HotStuf instances in parallel (where each
process is the leader of one such instance) and account for
the overall throughput across all instances, which in practice
equates to running  independent blockchains. We opted
instead to consider the throughput of a single instance
deployed in the best possible scenario. In this scenario, Kauri?s
throughput is on par with the reported throughput of
ResilientDB, which is ? 55 / [
          <xref ref-type="bibr" rid="ref17">17</xref>
          ]. However, ResilientDB
performance is dictated by the number of clusters while Kauri
is independent of this factor. Moreover, ResilientDB tolerates
only  ? 3?1 , where  is the size of the smallest cluster
(§1), while Kauri tolerates  ? 3?1 faults as classical BFT.
        </p>
        <p>It is worth noting that, in heterogeneous networks, all
these protocols require some amount of manual
configuration for optimal performance (for instance, selecting the best
place for the leader and for internal nodes). Designing
methods to automatically find the best deployment configuration
for Kauri is left for future work.</p>
      </sec>
      <sec id="sec-7-10">
        <title>7.10 Reconfiguration</title>
        <p>Finally, we evaluate the reconfiguration time in the following
faulty scenarios: i) one faulty leader, ii) three consecutive
faulty leaders, and iii)  faulty interior or leader nodes. In the
ifrst two cases,  &lt; , thus Kauri keeps the tree topology,
while in the third case,  is large and hence Kauri needs to
fall back to a star. We empirically calibrate the fault detection
timeout, by starting with a large value and gradually
decreasing it until we found that further decreases would lead to
spurious reconfigurations in a stable system. This resulted
in a timeout of 0.35 for Kauri and 1.7 for HotStuf-secp.
This diference is explained by the fact that Kauri message
dissemination is more regular than HotStuf, due to
pipelining, and hence the fault detection timeout can be set more
aggressively. Figure 12 presents the results for a system with
 = 100 in the global scenario. We execute each system for
100 seconds (warm-up not shown), inject the fault at 40
seconds and measure the impact on the throughput. As we can
observe, for a small number of faults both systems recover to
the throughput levels before the fault in ? 5 seconds for one
faulty leader (Figure 12a) and ? 12 seconds for three
consecutive faulty leaders (Figure 12b). As shown, Kauri recovers
in the same time-frame as HotStuf.</p>
        <p>To assess the behavior of Kauri with a large number of
faulty nodes (i.e.  ) we set up two diferent scenarios depicted
in Figure 12c. In the first scenario (plot line labeled ?Kauri
leaders")  leaders fail in succession. As expected after 
reconfigurations Kauri has fallen back to a star and stabilizes
at around the same throughput of HotStuf. In the second
scenario (plot line labeled ?Kauri internal+leaders"), we start
by failing internal nodes of  consecutive trees such that no
consensus can be reached for any of these trees. This forces
Kauri to degrade to a star after  reconfigurations. Then,
we selected faulty processes to serve as leaders for the first
 star networks. This is possible because a faulty process
can prevent consensus from being reached in two diferent
configurations: if it is an internal node in a tree and if it is
subsequently picked as root node for a star. This scenario
constitutes the worst-case scenario for Kauri, causing  ++1
reconfigurations, as stated in Section 5.3. In this scenario, the
total recovery time is long because all configurations (except
the last) timeout. In detail, the timeout is initially set to 1.7,
doubled after each of the first two reconfigurations, and
subsequently capped at 10. Since  = 33 and  = 10, with
HotStuf we need a total of 1.7 + 3.4 + 6.8 + 10 · 30 = 311.9
to recover and with Kauri we need 10 · 10 = 100 more.
Nonetheless, after the system stabilizes the performance of
Kauri is at the same level as HotStuf.</p>
      </sec>
    </sec>
    <sec id="sec-8">
      <title>8 Conclusions and Future Work</title>
      <p>State-of-the-art permissioned blockchains sufer from
important limitations: bottlenecks resulting from work
concentration on the leader, throughput decrease when
implementing load distribution, or degraded resilience. Kauri
overcomes these limitations by introducing a novel pipelining
scheme that makes full use of the parallelization
opportunities provided by dissemination/ aggregation trees.
Furthermore, Kauri uses a reconfiguration strategy that preserves
the tree when the number of faults is smaller than the fanout,
while still ensuring that a robust configuration is found in
a linear number of steps for any number of faults  &lt;  /3.
In contrast with solutions based on committees, Kauri does
not compromise the resilience nor the finality of consensus.
Kauri?s throughput substantially outperforms HotStuf?s in
all considered scenarios, reaching up to 28x with only a
modest increase in latency. In bandwidth-constrained scenarios
Kauri outperforms HotStuf in both throughput and latency.
The current implementation of Kauri requires the topology of
the tree and the value of the pipelining stretch to be manually
configured, using the performance model provided in this
paper. We are currently working on algorithms to automate
and optimize these configurations.</p>
      <p>Acknowledgements: We thank our shepherd, Andreas Haeberlen, and
the anonymous reviewers for their help in improving the final version
of the manuscript. This work was partially supported by CAPES - Brazil
(Coordenação de Aperfeiçoamento de Pessoal de Nível Superior) and by
Fundação para a Ciência e Tecnologia (FCT) under project UIDB/50021/2020
and grant 2020.05270.BD, and via project COSMOS (via the OE with ref.
) 10
t/xs 89
t(uK 567
hpgou 432
rh 1
T 0
) 10
/txs 89
t(uK 675
0
10
20
30
40
60
70
80</p>
      <p>PTDC/EEI-COM/29271/2017 and via the ?Programa Operacional Regional de
Lisboa na sua componente FEDER? with ref. Lisboa-01-0145-FEDER-029271)
and project Angainor with reference LISBOA-01-0145-FEDER-031456.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <ref id="ref1">
        <mixed-citation>
          [1]
          <string-name>
            <given-names>Y.</given-names>
            <surname>Amir</surname>
          </string-name>
          ,
          <string-name>
            <given-names>C.</given-names>
            <surname>Danilov</surname>
          </string-name>
          ,
          <string-name>
            <given-names>D.</given-names>
            <surname>Dolev</surname>
          </string-name>
          ,
          <string-name>
            <given-names>J.</given-names>
            <surname>Kirsch</surname>
          </string-name>
          ,
          <string-name>
            <given-names>J.</given-names>
            <surname>Lane</surname>
          </string-name>
          ,
          <string-name>
            <given-names>C.</given-names>
            <surname>Nita-Rotaru</surname>
          </string-name>
          ,
          <string-name>
            <given-names>J.</given-names>
            <surname>Olsen</surname>
          </string-name>
          , and
          <string-name>
            <given-names>D.</given-names>
            <surname>Zage</surname>
          </string-name>
          .
          <year>2010</year>
          .
          <article-title>Steward: Scaling Byzantine Fault-Tolerant Replication to Wide Area Networks</article-title>
          .
          <source>IEEE TDSC 7</source>
          ,
          <issue>1</issue>
          (
          <year>2010</year>
          ),
          <fpage>80</fpage>
          -
          <lpage>93</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref2">
        <mixed-citation>
          [2]
          <string-name>
            <given-names>J.</given-names>
            <surname>Bernstein</surname>
          </string-name>
          ,
          <string-name>
            <given-names>T.</given-names>
            <surname>Lange</surname>
          </string-name>
          , et al.
          <year>2013</year>
          .
          <article-title>SafeCurves: choosing safe curves for elliptic-curve cryptography</article-title>
          . htp://safecurves.cr.yp.to
        </mixed-citation>
      </ref>
      <ref id="ref3">
        <mixed-citation>
          [3]
          <string-name>
            <given-names>A.</given-names>
            <surname>Bessani</surname>
          </string-name>
          ,
          <string-name>
            <given-names>J.</given-names>
            <surname>Sousa</surname>
          </string-name>
          , and
          <string-name>
            <surname>E. . Alchieri. 2014.</surname>
          </string-name>
          <article-title>State Machine Replication for the Masses with BFT-SMART</article-title>
          .
          <source>In DSN. Atlanta (GA)</source>
          , USA.
        </mixed-citation>
      </ref>
      <ref id="ref4">
        <mixed-citation>
          [4]
          <string-name>
            <given-names>D.</given-names>
            <surname>Boneh</surname>
          </string-name>
          ,
          <string-name>
            <given-names>B.</given-names>
            <surname>Lynn</surname>
          </string-name>
          , and
          <string-name>
            <given-names>H.</given-names>
            <surname>Shacham</surname>
          </string-name>
          .
          <year>2001</year>
          .
          <article-title>Short signatures from the Weil pairing</article-title>
          .
          <source>Asiacrypt'2001. LNCS 2248.</source>
        </mixed-citation>
      </ref>
      <ref id="ref5">
        <mixed-citation>
          [5]
          <string-name>
            <given-names>C.</given-names>
            <surname>Cachin</surname>
          </string-name>
          .
          <year>2016</year>
          .
          <article-title>Architecture of the Hyperledger Blockchain Fabric</article-title>
          . In DCCL. Chicago (IL), USA.
        </mixed-citation>
      </ref>
      <ref id="ref6">
        <mixed-citation>
          [6]
          <string-name>
            <given-names>C.</given-names>
            <surname>Cachin</surname>
          </string-name>
          ,
          <string-name>
            <given-names>R.</given-names>
            <surname>Guerraoui</surname>
          </string-name>
          , and
          <string-name>
            <given-names>L.</given-names>
            <surname>Rodrigues</surname>
          </string-name>
          .
          <year>2011</year>
          .
          <article-title>Introduction to Reliable and Secure Distributed Programming (2nd ed</article-title>
          .). Springer.
        </mixed-citation>
      </ref>
      <ref id="ref7">
        <mixed-citation>
          [7]
          <string-name>
            <given-names>M.</given-names>
            <surname>Castro</surname>
          </string-name>
          and
          <string-name>
            <given-names>B.</given-names>
            <surname>Liskov</surname>
          </string-name>
          .
          <year>1999</year>
          .
          <article-title>Practical Byzantine Fault Tolerance</article-title>
          .
          <source>In OSDI. New Orleans (LA)</source>
          , USA,
          <fpage>173</fpage>
          -
          <lpage>186</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref8">
        <mixed-citation>
          [8]
          <string-name>
            <given-names>B.</given-names>
            <surname>Cohen</surname>
          </string-name>
          and
          <string-name>
            <given-names>K.</given-names>
            <surname>Pietrzak</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>The chia network blockchain</article-title>
          . htps: //www.chia.net/assets/ChiaGreenPaper.pdf
        </mixed-citation>
      </ref>
      <ref id="ref9">
        <mixed-citation>
          [9]
          <string-name>
            <surname>M.</surname>
          </string-name>
          <source>del Castillo</source>
          .
          <year>2020</year>
          .
          <article-title>Forbes Blockchain 50</article-title>
          . htps://www. forbes.com/sites/michaeldelcastillo/2020/02/19/blockchain50/?sh=77ed26207553
        </mixed-citation>
      </ref>
      <ref id="ref10">
        <mixed-citation>
          [10]
          <string-name>
            <given-names>C.</given-names>
            <surname>Dwork</surname>
          </string-name>
          ,
          <string-name>
            <given-names>N.</given-names>
            <surname>Lynch</surname>
          </string-name>
          , and
          <string-name>
            <given-names>L.</given-names>
            <surname>Stockmeyer</surname>
          </string-name>
          .
          <year>1988</year>
          .
          <article-title>Consensus in the Presence of Partial Synchrony</article-title>
          .
          <source>J. ACM</source>
          <volume>35</volume>
          ,
          <issue>2</issue>
          (April
          <year>1988</year>
          ),
          <fpage>288</fpage>
          -
          <lpage>323</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref11">
        <mixed-citation>
          [11]
          <string-name>
            <given-names>M.</given-names>
            <surname>Eischer</surname>
          </string-name>
          and
          <string-name>
            <given-names>T.</given-names>
            <surname>Distler</surname>
          </string-name>
          .
          <year>2018</year>
          .
          <article-title>Latency-Aware Leader Selection for Geo-Replicated Byzantine Fault-Tolerant Systems</article-title>
          . In DSN-W. Luxembourg City, Luxembourg,
          <fpage>140</fpage>
          -
          <lpage>145</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref12">
        <mixed-citation>
          [12]
          <string-name>
            <given-names>D.</given-names>
            <surname>Balouek</surname>
          </string-name>
          et al.
          <year>2013</year>
          .
          <article-title>Adding Virtualization Capabilities to the Grid'5000 Testbed</article-title>
          . In Cloud Computing and
          <string-name>
            <given-names>Services</given-names>
            <surname>Science</surname>
          </string-name>
          , I. Ivanov, M. van
          <string-name>
            <surname>Sinderen</surname>
            ,
            <given-names>F.</given-names>
          </string-name>
          <string-name>
            <surname>Leymann</surname>
          </string-name>
          , and T. Shan (Eds.).
          <source>Communications in Computer and Information Science</source>
          , Vol.
          <volume>367</volume>
          . Springer,
          <fpage>3</fpage>
          -
          <lpage>20</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref13">
        <mixed-citation>
          [13]
          <string-name>
            <given-names>Z.</given-names>
            <surname>Amsden</surname>
          </string-name>
          et al.
          <year>2020</year>
          .
          <article-title>The Diem Blockchain</article-title>
          . htps://developers.diem. com/docs/technical-papers/
          <article-title>the-diem-blockchain-paper/.</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref14">
        <mixed-citation>
          [14]
          <string-name>
            <given-names>M.</given-names>
            <surname>Fischer</surname>
          </string-name>
          ,
          <string-name>
            <given-names>N.</given-names>
            <surname>Lynch</surname>
          </string-name>
          , and
          <string-name>
            <given-names>M.</given-names>
            <surname>Paterson</surname>
          </string-name>
          .
          <year>1985</year>
          .
          <article-title>Impossibility of Distributed Consensus with One Faulty Process</article-title>
          .
          <source>J. ACM</source>
          <volume>32</volume>
          ,
          <issue>2</issue>
          (April
          <year>1985</year>
          ),
          <fpage>374</fpage>
          -
          <lpage>382</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref15">
        <mixed-citation>
          [15]
          <string-name>
            <given-names>Y.</given-names>
            <surname>Gilad</surname>
          </string-name>
          ,
          <string-name>
            <given-names>R.</given-names>
            <surname>Hemo</surname>
          </string-name>
          ,
          <string-name>
            <given-names>S.</given-names>
            <surname>Micali</surname>
          </string-name>
          , G. Vlachos, and
          <string-name>
            <given-names>N.</given-names>
            <surname>Zeldovich</surname>
          </string-name>
          .
          <year>2017</year>
          .
          <article-title>Algorand: Scaling Byzantine Agreements for Cryptocurrencies</article-title>
          . In SOSP. Shanghai, China,
          <fpage>51</fpage>
          -
          <lpage>68</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref16">
        <mixed-citation>
          [16]
          <string-name>
            <given-names>G.</given-names>
            <surname>Gueta</surname>
          </string-name>
          , I. Abraham,
          <string-name>
            <given-names>S.</given-names>
            <surname>Grossman</surname>
          </string-name>
          ,
          <string-name>
            <given-names>D.</given-names>
            <surname>Malkhi</surname>
          </string-name>
          ,
          <string-name>
            <given-names>B.</given-names>
            <surname>Pinkas</surname>
          </string-name>
          ,
          <string-name>
            <given-names>M.</given-names>
            <surname>Reiter</surname>
          </string-name>
          ,
          <string-name>
            <given-names>D.</given-names>
            <surname>Seredinschi</surname>
          </string-name>
          ,
          <string-name>
            <given-names>O.</given-names>
            <surname>Tamir</surname>
          </string-name>
          ,
          <article-title>and</article-title>
          <string-name>
            <given-names>A.</given-names>
            <surname>Tomescu</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>SBFT: A Scalable and Decentralized Trust Infrastructure</article-title>
          .
          <source>In DSN. Portland (OR)</source>
          , USA.
        </mixed-citation>
      </ref>
      <ref id="ref17">
        <mixed-citation>
          [17]
          <string-name>
            <given-names>S.</given-names>
            <surname>Gupta</surname>
          </string-name>
          ,
          <string-name>
            <given-names>S.</given-names>
            <surname>Rahnama</surname>
          </string-name>
          ,
          <string-name>
            <given-names>J.</given-names>
            <surname>Hellings</surname>
          </string-name>
          , and
          <string-name>
            <given-names>M.</given-names>
            <surname>Sadoghi</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>ResilientDB: Global Scale Resilient Blockchain Fabric</article-title>
          .
          <source>Proc. VLDB Endow</source>
          .
          <volume>13</volume>
          ,
          <issue>6</issue>
          (Feb.
          <year>2020</year>
          ),
          <fpage>868</fpage>
          -
          <lpage>883</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref18">
        <mixed-citation>
          [18]
          <string-name>
            <given-names>S.</given-names>
            <surname>Hemminger</surname>
          </string-name>
          .
          <year>2005</year>
          .
          <article-title>Network Emulation with NetEm</article-title>
          .
          <source>In Proc. of the 6th Australia's National Linux Conference (LCA2005)</source>
          . Canberra, Australia.
        </mixed-citation>
      </ref>
      <ref id="ref19">
        <mixed-citation>
          [19]
          <string-name>
            <given-names>E.</given-names>
            <surname>Kokoris-Kogias</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>Robust and scalable consensus for sharded distributed ledgers</article-title>
          .
          <source>Technical Report. Tech. rep., Cryptology ePrint Archive, Report</source>
          <year>2019</year>
          /676.
        </mixed-citation>
      </ref>
      <ref id="ref20">
        <mixed-citation>
          [20]
          <string-name>
            <given-names>E.</given-names>
            <surname>Kokoris-Kogias</surname>
          </string-name>
          ,
          <string-name>
            <given-names>P.</given-names>
            <surname>Jovanovic</surname>
          </string-name>
          ,
          <string-name>
            <given-names>N.</given-names>
            <surname>Gailly</surname>
          </string-name>
          ,
          <string-name>
            <surname>I. Khofi</surname>
          </string-name>
          ,
          <string-name>
            <given-names>L.</given-names>
            <surname>Gasser</surname>
          </string-name>
          , and
          <string-name>
            <given-names>B.</given-names>
            <surname>Ford</surname>
          </string-name>
          .
          <year>2016</year>
          .
          <article-title>Enhancing Bitcoin Security and Performance with Strong Consistency via Collective Signing</article-title>
          . In USENIX Security. Austin (TX), USA,
          <fpage>279</fpage>
          -
          <lpage>296</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref21">
        <mixed-citation>
          [21]
          <string-name>
            <given-names>E.</given-names>
            <surname>Kokoris-Kogias</surname>
          </string-name>
          ,
          <string-name>
            <given-names>P.</given-names>
            <surname>Jovanovic</surname>
          </string-name>
          ,
          <string-name>
            <given-names>L.</given-names>
            <surname>Gasser</surname>
          </string-name>
          ,
          <string-name>
            <given-names>N.</given-names>
            <surname>Gailly</surname>
          </string-name>
          , E. Syta, and
          <string-name>
            <given-names>B.</given-names>
            <surname>Ford</surname>
          </string-name>
          .
          <year>2018</year>
          .
          <article-title>OmniLedger: A Secure, Scale-Out, Decentralized Ledger via Sharding</article-title>
          . In
          <string-name>
            <surname>S</surname>
          </string-name>
          &amp;P. San Francisco (CA), USA,
          <fpage>583</fpage>
          -
          <lpage>598</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref22">
        <mixed-citation>
          [22]
          <string-name>
            <given-names>L.</given-names>
            <surname>Lamport</surname>
          </string-name>
          ,
          <string-name>
            <given-names>R.</given-names>
            <surname>Shostak</surname>
          </string-name>
          , and
          <string-name>
            <given-names>M.</given-names>
            <surname>Pease</surname>
          </string-name>
          .
          <year>1982</year>
          .
          <article-title>The Byzantine Generals Problem</article-title>
          .
          <source>TOPLAS 4</source>
          ,
          <issue>3</issue>
          (
          <year>July 1982</year>
          ),
          <fpage>382</fpage>
          -
          <lpage>401</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref23">
        <mixed-citation>
          [23]
          <string-name>
            <given-names>W.</given-names>
            <surname>Li</surname>
          </string-name>
          ,
          <string-name>
            <given-names>C.</given-names>
            <surname>Feng</surname>
          </string-name>
          ,
          <string-name>
            <given-names>L.</given-names>
            <surname>Zhang</surname>
          </string-name>
          ,
          <string-name>
            <given-names>H.</given-names>
            <surname>Xu</surname>
          </string-name>
          ,
          <string-name>
            <given-names>B.</given-names>
            <surname>Cao</surname>
          </string-name>
          , and
          <string-name>
            <given-names>M.</given-names>
            <surname>Imran</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>A Scalable Multi-Layer PBFT Consensus for Blockchain</article-title>
          .
          <source>IEEE Transactions on Parallel and Distributed Systems</source>
          <volume>32</volume>
          ,
          <issue>5</issue>
          (
          <year>2021</year>
          ),
          <fpage>1146</fpage>
          -
          <lpage>1160</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref24">
        <mixed-citation>
          [24]
          <string-name>
            <given-names>D.</given-names>
            <surname>Mazieres</surname>
          </string-name>
          .
          <year>2015</year>
          .
          <article-title>The stellar consensus protocol: A federated model for internet-level consensus</article-title>
          .
          <source>Stellar Development Foundation</source>
          <volume>32</volume>
          (
          <year>2015</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref25">
        <mixed-citation>
          [25]
          <string-name>
            <given-names>R.</given-names>
            <surname>Neiheiser</surname>
          </string-name>
          ,
          <string-name>
            <given-names>D.</given-names>
            <surname>Presser</surname>
          </string-name>
          ,
          <string-name>
            <given-names>L.</given-names>
            <surname>Rech</surname>
          </string-name>
          ,
          <string-name>
            <given-names>M.</given-names>
            <surname>Bravo</surname>
          </string-name>
          ,
          <string-name>
            <given-names>L.</given-names>
            <surname>Rodrigues</surname>
          </string-name>
          , and
          <string-name>
            <given-names>M.</given-names>
            <surname>Correia</surname>
          </string-name>
          .
          <year>2018</year>
          .
          <article-title>Fireplug: Flexible and robust N-version geo-replication of graph databases</article-title>
          .
          <source>In ICOIN. Chiang Mai</source>
          , Thailand,
          <fpage>110</fpage>
          -
          <lpage>115</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref26">
        <mixed-citation>
          [26]
          <fpage>R3</fpage>
          . Corda Platform. htps://www.r3.com/corda-platform/.
        </mixed-citation>
      </ref>
      <ref id="ref27">
        <mixed-citation>
          [27]
          <string-name>
            <given-names>T.</given-names>
            <surname>Ristenpart</surname>
          </string-name>
          and
          <string-name>
            <given-names>S.</given-names>
            <surname>Yilek</surname>
          </string-name>
          .
          <year>2007</year>
          .
          <article-title>The Power of Proofs-of-Possession: Securing Multiparty Signatures against Rogue-Key Attacks</article-title>
          . In EUROCRYPT, M. Naor (Ed.). Springer,
          <fpage>228</fpage>
          -
          <lpage>245</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref28">
        <mixed-citation>
          [28]
          <string-name>
            <given-names>C.</given-names>
            <surname>Stathakopoulou</surname>
          </string-name>
          ,
          <string-name>
            <given-names>T.</given-names>
            <surname>David</surname>
          </string-name>
          , and
          <string-name>
            <given-names>M.</given-names>
            <surname>Vukolic</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>Mir-BFT: High-Throughput BFT for Blockchains</article-title>
          . CoRR abs/
          <year>1906</year>
          .05552 (
          <year>2019</year>
          ).
          <year>arxiv1906</year>
          .05552 htp://arxiv.org/abs/
          <year>1906</year>
          .05552
        </mixed-citation>
      </ref>
      <ref id="ref29">
        <mixed-citation>
          [29]
          <string-name>
            <given-names>G.</given-names>
            <surname>Veronese</surname>
          </string-name>
          ,
          <string-name>
            <given-names>M.</given-names>
            <surname>Correia</surname>
          </string-name>
          ,
          <string-name>
            <given-names>A.</given-names>
            <surname>Bessani</surname>
          </string-name>
          , and
          <string-name>
            <given-names>L.</given-names>
            <surname>Lung</surname>
          </string-name>
          .
          <year>2009</year>
          .
          <article-title>Spin One's Wheels? Byzantine Fault Tolerance with a Spinning Primary</article-title>
          .
          <source>In SRDS. Niagara Falls (NY)</source>
          , USA.
        </mixed-citation>
      </ref>
      <ref id="ref30">
        <mixed-citation>
          [30]
          <string-name>
            <given-names>G.</given-names>
            <surname>Veronese</surname>
          </string-name>
          ,
          <string-name>
            <given-names>M.</given-names>
            <surname>Correia</surname>
          </string-name>
          ,
          <string-name>
            <given-names>A.</given-names>
            <surname>Bessani</surname>
          </string-name>
          , and
          <string-name>
            <given-names>L.</given-names>
            <surname>Lung</surname>
          </string-name>
          .
          <year>2010</year>
          .
          <article-title>EBAWA: Eficient Byzantine Agreement for Wide-Area Networks</article-title>
          . In HASE. San Jose (CA), USA,
          <fpage>10</fpage>
          -
          <lpage>19</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref31">
        <mixed-citation>
          [31]
          <string-name>
            <given-names>M.</given-names>
            <surname>Vukoli?</surname>
          </string-name>
          .
          <year>2015</year>
          .
          <article-title>The Quest for Scalable Blockchain Fabric: Proof-ofWork vs</article-title>
          .
          <source>BFT Replication</source>
          . In iNetSec. Zurich, Switzerland.
        </mixed-citation>
      </ref>
      <ref id="ref32">
        <mixed-citation>
          [32]
          <string-name>
            <given-names>P.</given-names>
            <surname>Wuille</surname>
          </string-name>
          .
          <year>2018</year>
          . libsecp256k1. htps://github.com/bitcoin/secp256k1
        </mixed-citation>
      </ref>
      <ref id="ref33">
        <mixed-citation>
          [33]
          <string-name>
            <given-names>M.</given-names>
            <surname>Yin</surname>
          </string-name>
          ,
          <string-name>
            <given-names>D.</given-names>
            <surname>Malkhi</surname>
          </string-name>
          ,
          <string-name>
            <given-names>M.</given-names>
            <surname>Reiter</surname>
          </string-name>
          , G. Gueta,
          <string-name>
            <given-names>and I.</given-names>
            <surname>Abraham</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>HotStuf: BFT Consensus with Linearity and Responsiveness</article-title>
          . In PODC. Toronto (ON),
          <year>Canada</year>
          ,
          <fpage>347</fpage>
          -
          <lpage>356</lpage>
          .
        </mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>

